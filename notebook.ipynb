{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resize png to be smaller by a factor of 4 to fit in GPU'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"resize png to be smaller by a factor of 4 to fit in GPU\"\"\"\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# path = \"radpng\"\n",
    "# resize_ratio = 0.25  # where 0.5 is half size, 2 is double size\n",
    "\n",
    "# def resize_aspect_fit():\n",
    "#     dirs = os.listdir(path)\n",
    "#     for item in dirs:\n",
    "#         image = Image.open(path+item)\n",
    "#         file_path, extension = os.path.splitext(path+item)\n",
    "\n",
    "#         new_image_height = int(image.size[0] / (1/resize_ratio))\n",
    "#         new_image_length = int(image.size[1] / (1/resize_ratio))\n",
    "\n",
    "#         image = image.resize((new_image_height, new_image_length), Image.ANTIALIAS)\n",
    "#         image.save(file_path + \"_small\" + extension, 'PNG', quality=90)\n",
    "\n",
    "\n",
    "# resize_aspect_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing generation 0...\n",
      "Processing generation 50...\n",
      "Processing generation 100...\n",
      "Processing generation 150...\n",
      "Processing generation 200...\n",
      "Processing generation 250...\n",
      "Processing generation 300...\n",
      "Processing generation 350...\n",
      "Processing generation 400...\n",
      "Processing generation 450...\n",
      "Image saved to output_image.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "# Constants\n",
    "NUM_INDIVIDUALS = 1\n",
    "NUM_GENERATIONS = 500\n",
    "NUM_RADICALS = 1\n",
    "\n",
    "radicals_directory = \"radpng210\"\n",
    "radical_files = [f for f in os.listdir(radicals_directory) if f.endswith('.png')]\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Load the target line art and kanji radicals\n",
    "target = Image.open(\"myart.jpg\").convert('L')\n",
    "target_tensor = torch.tensor(np.array(target, dtype=np.float32)).to(device)\n",
    "kanji_radicals = [torch.tensor(np.array(Image.open(os.path.join(radicals_directory, f)).convert('L'), dtype=np.float32)).to(device) for f in radical_files]\n",
    "\n",
    "max_x = target.width - 400\n",
    "max_y = target.height - 400\n",
    "\n",
    "# Initialization\n",
    "def create_individual():\n",
    "    individual = []\n",
    "    for _ in range(NUM_RADICALS):\n",
    "        radical = random.choice(kanji_radicals)\n",
    "        x = random.randint(0, max_x)\n",
    "        y = random.randint(0, max_y)\n",
    "        size = random.uniform(0.5, 1.5)\n",
    "        individual.append((radical, x, y, size))\n",
    "    return individual\n",
    "\n",
    "\n",
    "population = [create_individual() for _ in range(NUM_INDIVIDUALS)]\n",
    "\n",
    "# Fitness function\n",
    "def fitness(individual):\n",
    "    canvas = torch.ones_like(target_tensor) * 255\n",
    "    for radical, x, y, size in individual:\n",
    "        scaled_radical = torch.nn.functional.interpolate(radical.unsqueeze(0).unsqueeze(0), scale_factor=size, mode='bilinear').squeeze()\n",
    "\n",
    "        # Clamp positions and sizes to ensure they don't go out of bounds\n",
    "        y_end = min(y + scaled_radical.shape[0], canvas.shape[0])\n",
    "        x_end = min(x + scaled_radical.shape[1], canvas.shape[1])\n",
    "        \n",
    "        scaled_radical = scaled_radical[:y_end-y, :x_end-x]\n",
    "\n",
    "        canvas[y:y_end, x:x_end] = canvas[y:y_end, x:x_end] * (1 - scaled_radical/255.0)\n",
    "\n",
    "\n",
    "\n",
    "    error = torch.sum((canvas - target_tensor)**2)\n",
    "    return -error.item()\n",
    "\n",
    "\n",
    "# Selection, Crossover, and Mutation\n",
    "def crossover(parent1, parent2):\n",
    "    split = random.randint(0, NUM_RADICALS-1)\n",
    "    child = parent1[:split] + parent2[split:]\n",
    "    return child\n",
    "\n",
    "def mutate(individual):\n",
    "    idx = random.randint(0, NUM_RADICALS-1)\n",
    "    individual[idx] = (random.choice(kanji_radicals), random.randint(0, target.width), random.randint(0, target.height), random.uniform(0.5, 1.5))\n",
    "    return individual\n",
    "\n",
    "# Evolution\n",
    "for generation in range(NUM_GENERATIONS):\n",
    "    if generation % 50 == 0:\n",
    "        print(f\"Processing generation {generation}...\")\n",
    "    population.sort(key=fitness, reverse=True)\n",
    "    new_population = population[:10]\n",
    "    while len(new_population) < NUM_INDIVIDUALS:\n",
    "        parent1 = random.choice(population[:10])\n",
    "        parent2 = random.choice(population[:10])\n",
    "        child = crossover(parent1, parent2)\n",
    "        if random.random() < 0.1:\n",
    "            child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = new_population\n",
    "\n",
    "# Display the best individual\n",
    "best = population[0]\n",
    "canvas = torch.ones_like(target_tensor) * 255\n",
    "for radical, x, y, size in best:\n",
    "    scaled_radical = torch.nn.functional.interpolate(radical.unsqueeze(0).unsqueeze(0), scale_factor=size, mode='bilinear').squeeze()\n",
    "\n",
    "    # Clamp positions and sizes to ensure they don't go out of bounds\n",
    "    y_end = min(y + scaled_radical.shape[0], canvas.shape[0])\n",
    "    x_end = min(x + scaled_radical.shape[1], canvas.shape[1])\n",
    "    \n",
    "    scaled_radical = scaled_radical[:y_end-y, :x_end-x]\n",
    "\n",
    "    canvas[y:y_end, x:x_end] -= scaled_radical\n",
    "\n",
    "Image.fromarray(canvas.cpu().numpy().astype(np.uint8)).show()\n",
    "output_path = \"output_image.png\"\n",
    "Image.fromarray(canvas.cpu().numpy().astype(np.uint8)).save(output_path)\n",
    "print(f\"Image saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_radical_as_tensor(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # If image has an alpha channel (transparency)\n",
    "    if img.mode == 'RGBA':\n",
    "        r, g, b, a = img.split()\n",
    "        bg = Image.new('RGB', img.size, (255, 255, 255))  # Pure white background\n",
    "        bg.paste(img, (0, 0), a)  # Paste image over white background where it's not transparent\n",
    "        img = bg\n",
    "        \n",
    "    return torch.tensor(np.array(img.convert('L'), dtype=np.float32)).to(device)\n",
    "\n",
    "kanji_radicals = [load_radical_as_tensor(os.path.join(radicals_directory, f)) for f in radical_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing generation 0...\n",
      "Processing generation 50...\n",
      "Processing generation 100...\n",
      "Processing generation 150...\n",
      "Processing generation 200...\n",
      "Processing generation 250...\n",
      "Processing generation 300...\n",
      "Processing generation 350...\n",
      "Processing generation 400...\n",
      "Processing generation 450...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "NUM_INDIVIDUALS = len(radical_files)  # Set the number of individuals equal to the number of radicals\n",
    "NUM_GENERATIONS = 500\n",
    "NUM_RADICALS = 1  # Each individual will now represent just one radical\n",
    "\n",
    "radicals_directory = \"radpng\"\n",
    "radical_files = [f for f in os.listdir(radicals_directory) if f.endswith('.png')]\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the target line art and kanji radicals\n",
    "target = Image.open(\"myart.jpg\").convert('L')\n",
    "target_tensor = torch.tensor(np.array(target, dtype=np.float32)).to(device)\n",
    "# kanji_radicals = [torch.tensor(np.array(Image.open(os.path.join(radicals_directory, f)).convert('L'), dtype=np.float32)).to(device) for f in radical_files]\n",
    "\n",
    "max_x = target.width - 400\n",
    "max_y = target.height - 400\n",
    "\n",
    "# Initialization\n",
    "def create_individual():\n",
    "    radical = random.choice(kanji_radicals)\n",
    "    x = random.randint(0, max_x)\n",
    "    y = random.randint(0, max_y)\n",
    "    size = random.uniform(0.5, 1.5)\n",
    "    return [(radical, x, y, size)]\n",
    "\n",
    "population = [create_individual() for _ in range(NUM_INDIVIDUALS)]\n",
    "# Fitness function\n",
    "def fitness(individual):\n",
    "    canvas = torch.ones_like(target_tensor) * 255\n",
    "    for radical, x, y, size in individual:\n",
    "        scaled_radical = torch.nn.functional.interpolate(radical.unsqueeze(0).unsqueeze(0), scale_factor=size, mode='bilinear').squeeze()\n",
    "\n",
    "        # Clamp positions and sizes to ensure they don't go out of bounds\n",
    "        y_end = min(y + scaled_radical.shape[0], canvas.shape[0])\n",
    "        x_end = min(x + scaled_radical.shape[1], canvas.shape[1])\n",
    "        \n",
    "        scaled_radical = scaled_radical[:y_end-y, :x_end-x]\n",
    "\n",
    "        canvas[y:y_end, x:x_end] = canvas[y:y_end, x:x_end] * (scaled_radical/255.0)\n",
    "\n",
    "\n",
    "\n",
    "    error = torch.sum((canvas - target_tensor)**2)\n",
    "    return -error.item()\n",
    "\n",
    "\n",
    "# Selection, Crossover, and Mutation\n",
    "def crossover(parent1, parent2):\n",
    "    split = random.randint(0, NUM_RADICALS-1)\n",
    "    child = parent1[:split] + parent2[split:]\n",
    "    return child\n",
    "\n",
    "\n",
    "def mutate(individual):\n",
    "    individual[0] = (random.choice(kanji_radicals), random.randint(0, target.width), random.randint(0, target.height), random.uniform(0.5, 1.5))\n",
    "    return individual\n",
    "\n",
    "for generation in range(NUM_GENERATIONS):\n",
    "    if generation % 50 == 0:\n",
    "        print(f\"Processing generation {generation}...\")\n",
    "    population.sort(key=fitness, reverse=True)\n",
    "    new_population = population[:10]\n",
    "    while len(new_population) < NUM_INDIVIDUALS:\n",
    "        parent1 = random.choice(population[:10])\n",
    "        parent2 = random.choice(population[:10])\n",
    "        child = crossover(parent1, parent2)\n",
    "        if random.random() < 0.1:\n",
    "            child = mutate(child)\n",
    "        new_population.append(child)\n",
    "    population = new_population\n",
    "\n",
    "# Display the best individual\n",
    "best = population[0]\n",
    "canvas = torch.ones_like(target_tensor) * 255\n",
    "for radical, x, y, size in best:\n",
    "    scaled_radical = torch.nn.functional.interpolate(radical.unsqueeze(0).unsqueeze(0), scale_factor=size, mode='bilinear').squeeze()\n",
    "\n",
    "    # Clamp positions and sizes to ensure they don't go out of bounds\n",
    "    y_end = min(y + scaled_radical.shape[0], canvas.shape[0])\n",
    "    x_end = min(x + scaled_radical.shape[1], canvas.shape[1])\n",
    "    \n",
    "    scaled_radical = scaled_radical[:y_end-y, :x_end-x]\n",
    "\n",
    "    canvas[y:y_end, x:x_end] = canvas[y:y_end, x:x_end] * (scaled_radical/255.0)\n",
    "\n",
    "Image.fromarray(canvas.cpu().numpy().astype(np.uint8)).show()\n",
    "output_path = \"output_image.png\"\n",
    "# Image.fromarray(canvas.cpu().numpy().astype(np.uint8)).save(output_path)\n",
    "# print(f\"Image saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
